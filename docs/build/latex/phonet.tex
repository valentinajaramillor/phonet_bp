%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
 \ifdefined\DeclareUnicodeCharacterAsOptional\else
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
\fi\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}

\usepackage{geometry}
\usepackage{multirow}
\usepackage{eqparbox}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{2}



\title{phonet Documentation}
\date{Jun 18, 2020}
\release{0.3}
\author{Camilo Vasquez}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\begin{document}

\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{index::doc}}


This toolkit compute posteriors probabilities of phonological classes from audio files for several groups of phonemes according to the mode and manner of articulation.

If you are not sure about what phonological classes are, have a look at this
\sphinxhref{http://research.cs.tamu.edu/prism/lectures/sp/l3.pdf}{Phonological classes tutorial}

The code for this project is available at \sphinxurl{https://github.com/jcvasquezc/phonet} .

The list of the phonological classes available and the phonemes that are activated for each phonological class are observed in the following Table

\noindent\begin{tabulary}{\linewidth}{|L|L|}
\hline
\sphinxstylethead{\relax 
Phonological class
\unskip}\relax &\sphinxstylethead{\relax 
Phonemes
\unskip}\relax \\
\hline
vocalic
&
/a/, /e/, /i/, /o/, /u/
\\
\hline
consonantal
&
/b/, /tS/, /d/, /f/, /g/, /x/, /k/, /l/, /ʎ/, /m/, /n/, /p/, /ɾ/, /r/, /s/, /t/
\\
\hline
back
&
/a/, /o/, /u/
\\
\hline
anterior
&
/e/, /i/
\\
\hline
open
&
/a/, /e/, /o/
\\
\hline
close
&
/i/, /u/
\\
\hline
nasal
&
/m/, /n/
\\
\hline
stop
&
/p/, /b/, /t/, /k/, /g/, /tS/, /d/
\\
\hline
continuant
&
/f/, /b/, /tS/, /d/, /s/, /g/, /ʎ/, /x/
\\
\hline
lateral
&
/l/
\\
\hline
flap
&
/ɾ/
\\
\hline
trill
&
/r/
\\
\hline
voiced
&
/a/, /e/, /i/, /o/, /u/, /b/, /d/, /l/, /m/, /n/, /r/, /g/, /ʎ/
\\
\hline
strident
&
/f/, /s/, /tS/
\\
\hline
labial
&
/m/, /p/, /b/, /f/
\\
\hline
dental
&
/t/, /d/
\\
\hline
velar
&
/k/, /g/, /x/
\\
\hline
pause
&
/sil/
\\
\hline\end{tabulary}



\chapter{Need Help?}
\label{\detokenize{help::doc}}\label{\detokenize{help:welcome-to-phonet-s-documentation}}\label{\detokenize{help:need-help}}
If you have trouble with Phonet, please write to Camilo Vasquez at: \sphinxhref{mailto:juan.vasquez@fau.de}{juan.vasquez@fau.de}


\chapter{References}
\label{\detokenize{reference:references}}\label{\detokenize{reference::doc}}
If you use Phonet for research purposes, please cite the following paper:

Vásquez-Correa, J. C., Klumpp, P., Orozco-Arroyave, J. R., \& Nöth, E. (2019). Phonet: a Tool Based on Gated Recurrent Neural Networks to Extract Phonological Posteriors from Speech. Proc. Interspeech 2019, 549-553.

\sphinxhref{https://pdfs.semanticscholar.org/026f/3d631516466db0c27b599fb8b6dea987165e.pdf}{Download paper}

Supported features:
\begin{itemize}
\item {} 
\sphinxcode{phonet.model()} - This is the architecture used for the estimation of the phonological classes using a multitask learning strategy. It consists of a 2 Bidirectional GRU layers, followed by a time-distributed dense layer

\item {} 
\sphinxcode{phonet.get\_phon\_wav()} - Estimate the phonological classes using the BGRU models for an audio file (.wav)

\item {} 
\sphinxcode{phonet.get\_phon\_path()} - Estimate the phonological classes using the BGRU models for all the (.wav) audio files included inside a directory.

\item {} 
\sphinxcode{phonet.get\_posteriorgram()} - Estimate the posteriorgram for an audio file (.wav) sampled at 16kHz.

\item {} 
\sphinxcode{phonet.get\_PLLR()} - Estimate the phonological log-likelihood ratio (PLLR) features for an audio file (.wav) sampled at 16kHz.

\end{itemize}


\chapter{Installation}
\label{\detokenize{index:installation}}
From the source file:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{git} \PYG{n}{clone} \PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{jcvasquezc}\PYG{o}{/}\PYG{n}{phonet}
\PYG{n}{cd} \PYG{n}{phonet}
\PYG{n}{python} \PYG{n}{setup}\PYG{o}{.}\PYG{n}{py} \PYG{n}{install}
\end{sphinxVerbatim}


\chapter{Methods}
\label{\detokenize{index:methods}}\label{\detokenize{index:module-phonet}}\index{phonet (module)}
Compute posteriors probabilities of phonological classes from audio files for several groups of phonemes according to the mode and manner of articulation.
\begin{description}
\item[{@author: J. C. Vasquez-Correa}] \leavevmode
Pattern recognition Lab, University of Erlangen-Nuremberg
Faculty of Engineering, University of Antioquia,
\sphinxhref{mailto:juan.vasquez@fau.de}{juan.vasquez@fau.de}

\end{description}
\index{Phonet (class in phonet)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:phonet.Phonet}}\pysiglinewithargsret{\sphinxstrong{class }\sphinxcode{phonet.}\sphinxbfcode{Phonet}}{\emph{phonological\_classes}}{}
Phonet computes posteriors probabilities of phonological classes from audio files for several groups of phonemes.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{phonological\_classes} -- phonological class to be evaluated (\sphinxquotedblleft{}consonantal\sphinxquotedblright{}, \sphinxquotedblleft{}back\sphinxquotedblright{}, \sphinxquotedblleft{}anterior\sphinxquotedblright{}, \sphinxquotedblleft{}open\sphinxquotedblright{}, \sphinxquotedblleft{}close\sphinxquotedblright{}, \sphinxquotedblleft{}nasal\sphinxquotedblright{}, \sphinxquotedblleft{}stop\sphinxquotedblright{},
\sphinxquotedblleft{}continuant\sphinxquotedblright{},  \sphinxquotedblleft{}lateral\sphinxquotedblright{}, \sphinxquotedblleft{}flap\sphinxquotedblright{}, \sphinxquotedblleft{}trill\sphinxquotedblright{}, \sphinxquotedblleft{}voice\sphinxquotedblright{}, \sphinxquotedblleft{}strident\sphinxquotedblright{},
\sphinxquotedblleft{}labial\sphinxquotedblright{}, \sphinxquotedblleft{}dental\sphinxquotedblright{}, \sphinxquotedblleft{}velar\sphinxquotedblright{}, \sphinxquotedblleft{}pause\sphinxquotedblright{}, \sphinxquotedblleft{}vocalic\sphinxquotedblright{}, \sphinxquotedblleft{}all\sphinxquotedblright{}).

\item[{Returns}] \leavevmode
Phonet Object (see \sphinxhref{https://github.com/jcvasquezc/phonet/blob/master/example.py}{Examples}).

\end{description}\end{quote}

phonological\_classes=='all' computes the phonological posterior for the complete list of phonological classes.
\index{get\_PLLR() (phonet.Phonet method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:phonet.Phonet.get_PLLR}}\pysiglinewithargsret{\sphinxbfcode{get\_PLLR}}{\emph{audio\_file}, \emph{feat\_file='`}, \emph{projected=True}, \emph{plot\_flag=False}}{}
Estimate the phonological log-likelihood ratio (PLLR) features for an audio file (.wav) sampled at 16kHz
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{audio\_file} -- file audio (.wav) sampled at 16 kHz

\item {} 
\sphinxstyleliteralstrong{feat\_file} -- .csv file  to save the PLLR features for the phonological classes. Deafult=\sphinxquotedblright{}\sphinxquotedblright{} does not save the csv file

\end{itemize}

\item[{Projected}] \leavevmode
whether to make a projection of the feature space of the PLLR according to {[}1{]}, in order to avoid the bounding effect.

\item[{Plot\_flag}] \leavevmode
True or False. Plot distributions of the feature space

\item[{Returns}] \leavevmode
Pandas dataFrame with the PLLR features

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{phonet}\PYG{n+nn}{.}\PYG{n+nn}{phonet} \PYG{k+kn}{import} \PYG{n}{Phonet}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phon}\PYG{o}{=}\PYG{n}{Phonet}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{all}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{n}{PATH}\PYG{o}{+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/audios/sentence.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phon}\PYG{o}{.}\PYG{n}{get\PYGZus{}PLLR}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{)}
\end{sphinxVerbatim}

References:

{[}1{]} Diez, M., Varona, A., Penagarikano, M., Rodriguez-Fuentes, L. J., \& Bordel, G. (2014). On the projection of PLLRs for unbounded feature distributions in spoken language recognition. IEEE Signal Processing Letters, 21(9), 1073-1077.

{[}2{]} Abad, A., Ribeiro, E., Kepler, F., Astudillo, R. F., \& Trancoso, I. (2016). Exploiting Phone Log-Likelihood Ratio Features for the Detection of the Native Language of Non-Native English Speakers. In INTERSPEECH (pp. 2413-2417).

\end{fulllineitems}

\index{get\_feat() (phonet.Phonet method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:phonet.Phonet.get_feat}}\pysiglinewithargsret{\sphinxbfcode{get\_feat}}{\emph{signal}, \emph{fs}}{}
This method extracts log-Mel-filterbank energies used as inputs
of the model.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{signal} -- the audio signal from which to compute features. Should be an N array.

\item {} 
\sphinxstyleliteralstrong{fs} -- the sample rate of the signal we are working with, in Hz.

\end{itemize}

\item[{Returns}] \leavevmode
A numpy array of size (NUMFRAMES by 33 log-Mel-filterbank energies) containing features. Each row holds 1 feature vector.

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_phon\_path() (phonet.Phonet method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:phonet.Phonet.get_phon_path}}\pysiglinewithargsret{\sphinxbfcode{get\_phon\_path}}{\emph{audio\_path}, \emph{feat\_path}, \emph{plot\_flag=False}}{}
Estimate the phonological classes using the BGRU models for all the (.wav) audio files included inside a directory
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{audio\_path} -- directory with (.wav) audio files inside, sampled at 16 kHz

\item {} 
\sphinxstyleliteralstrong{feat\_path} -- directory were the computed phonological posteriros will be stores as a (.csv) file per (.wav) file from the input directory

\item {} 
\sphinxstyleliteralstrong{plot\_flag} -- True or False, whether you want plots of phonological classes or not

\end{itemize}

\item[{Returns}] \leavevmode
A directory with csv files created with the posterior probabilities for the phonological classes.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{phonet}\PYG{n+nn}{.}\PYG{n+nn}{phonet} \PYG{k+kn}{import} \PYG{n}{Phonet}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phon}\PYG{o}{=}\PYG{n}{Phonet}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vocalic}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{strident}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{nasal}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{back}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{stop}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{pause}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phon}\PYG{o}{.}\PYG{n}{get\PYGZus{}phon\PYGZus{}path}\PYG{p}{(}\PYG{n}{PATH}\PYG{o}{+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/audios/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{PATH}\PYG{o}{+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/phonclasses2/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{get\_phon\_wav() (phonet.Phonet method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:phonet.Phonet.get_phon_wav}}\pysiglinewithargsret{\sphinxbfcode{get\_phon\_wav}}{\emph{audio\_file}, \emph{feat\_file='`}, \emph{plot\_flag=True}}{}
Estimate the phonological classes using the BGRU models for an audio file (.wav)
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{audio\_file} -- file audio (.wav) sampled at 16 kHz

\item {} 
\sphinxstyleliteralstrong{feat\_file} -- . File (.csv) to save the posteriors for the phonological classes. Deafult=\sphinxquotedblright{}\sphinxquotedblright{} does not save the csv file

\item {} 
\sphinxstyleliteralstrong{plot\_flag} -- True or False, whether you want plots of phonological classes or not

\end{itemize}

\item[{Returns}] \leavevmode
A pandas dataFrame with the posterior probabilities for the phonological classes.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{phonet}\PYG{n+nn}{.}\PYG{n+nn}{phonet} \PYG{k+kn}{import} \PYG{n}{Phonet}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phon}\PYG{o}{=}\PYG{n}{Phonet}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{stop}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} get the \PYGZdq{}stop\PYGZdq{} phonological posterior from a single file}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{n}{PATH}\PYG{o}{+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/audios/pataka.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}feat}\PYG{o}{=}\PYG{n}{PATH}\PYG{o}{+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/phonclasses/pataka}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phon}\PYG{o}{.}\PYG{n}{get\PYGZus{}phon\PYGZus{}wav}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{file\PYGZus{}feat}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{n}{PATH}\PYG{o}{+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/audios/sentence.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}feat}\PYG{o}{=}\PYG{n}{PATH}\PYG{o}{+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/phonclasses/sentence\PYGZus{}nasal}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phon}\PYG{o}{=}\PYG{n}{Phonet}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{nasal}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} get the \PYGZdq{}nasal\PYGZdq{} phonological posterior from a single file}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phon}\PYG{o}{.}\PYG{n}{get\PYGZus{}phon\PYGZus{}wav}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{file\PYGZus{}feat}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{n}{PATH}\PYG{o}{+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/audios/sentence.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}feat}\PYG{o}{=}\PYG{n}{PATH}\PYG{o}{+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/phonclasses/sentence\PYGZus{}nasal}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phon}\PYG{o}{=}\PYG{n}{Phonet}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{strident}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{nasal}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{back}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} get \PYGZdq{}strident, nasal, and back\PYGZdq{} phonological posterior from a single file}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phon}\PYG{o}{.}\PYG{n}{get\PYGZus{}phon\PYGZus{}wav}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{file\PYGZus{}feat}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{get\_posteriorgram() (phonet.Phonet method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:phonet.Phonet.get_posteriorgram}}\pysiglinewithargsret{\sphinxbfcode{get\_posteriorgram}}{\emph{audio\_file}}{}
Estimate the posteriorgram for an audio file (.wav) sampled at 16kHz
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{audio\_file} -- file audio (.wav) sampled at 16 kHz

\item[{Returns}] \leavevmode
plot of the posteriorgram

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{phonet}\PYG{n+nn}{.}\PYG{n+nn}{phonet} \PYG{k+kn}{import} \PYG{n}{Phonet}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phon}\PYG{o}{=}\PYG{n}{Phonet}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vocalic}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{strident}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{nasal}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{back}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{stop}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{pause}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phon}\PYG{o}{.}\PYG{n}{get\PYGZus{}posteriorgram}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{mask\_correction() (phonet.Phonet method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:phonet.Phonet.mask_correction}}\pysiglinewithargsret{\sphinxbfcode{mask\_correction}}{\emph{posterior}, \emph{threshold=0.5}}{}
Implements a mask for a correction the posterior probabilities
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{posterior} -- phonological posterior.

\item {} 
\sphinxstyleliteralstrong{threshold} -- threshold for correction

\end{itemize}

\item[{Returns}] \leavevmode
Corrected phonological posterior.

\end{description}\end{quote}

\end{fulllineitems}

\index{model() (phonet.Phonet method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:phonet.Phonet.model}}\pysiglinewithargsret{\sphinxbfcode{model}}{\emph{input\_size}}{}
This is the architecture used for the estimation of the phonological classes using a multitask learning strategy
It consists of a 2 Bidirectional GRU layers, followed by a time-distributed dense layer
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{input\_size} -- size of input for the BGRU layers (number of features x sequence length).

\item[{Returns}] \leavevmode
A Keras model of a 2-layer BGRU neural network.

\end{description}\end{quote}

\end{fulllineitems}

\index{modelp() (phonet.Phonet method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:phonet.Phonet.modelp}}\pysiglinewithargsret{\sphinxbfcode{modelp}}{\emph{input\_size}}{}
This is the architecture used for phoneme recognition
It consists of a 2 Bidirectional GRU layers, followed by a time-distributed dense layer
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{input\_size} -- size of input for the BGRU layers (number of features x sequence length).

\item[{Returns}] \leavevmode
A Keras model of a 2-layer BGRU neural network.

\end{description}\end{quote}

\end{fulllineitems}

\index{number2phoneme() (phonet.Phonet method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:phonet.Phonet.number2phoneme}}\pysiglinewithargsret{\sphinxbfcode{number2phoneme}}{\emph{seq}}{}
Converts the prediction of the neural network for phoneme recognition to a list of phonemes.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{seq} -- sequence of integers obtained from the preiction of the neural network for phoneme recognition.

\item[{Returns}] \leavevmode
A list of strings of the phonemes recognized for each time-frame.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\chapter{Help}
\label{\detokenize{index:help}}
If you have trouble with Phonet, please write to Camilo Vasquez at: \sphinxhref{mailto:juan.vasquez@fau.de}{juan.vasquez@fau.de}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{p}
\item {\sphinxstyleindexentry{phonet}}\sphinxstyleindexpageref{index:\detokenize{module-phonet}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}